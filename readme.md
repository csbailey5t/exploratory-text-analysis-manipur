
# Table of Contents

1.  [Presenter](#org74233ec)
2.  [Exploratory text analysis](#org33ee07c)
3.  [Voyant](#orgddff2dc)
    1.  [Installing Voyant vs using the hosted web version](#org6debaa8)
    2.  [File types and corpus building](#org1415ed8)
    3.  [Exploring the interface](#org202cd54)
    4.  [Tools of note](#org0184ede)
    5.  [Exporting results](#orgab3fe6c)
4.  [Taguette](#org192ebad)
    1.  [Installing Taguette vs using the hosted web version](#org61e88e5)
    2.  [File types](#org8a3413f)
    3.  [Coding documents](#orgd2b0a76)
    4.  [Exporting results](#orgd2b5ab3)
5.  [Putting it together: between distant and close reading](#org7c69b03)
6.  [Resources:](#org74fc53d)



<a id="org74233ec"></a>

# Presenter

[Scott Bailey](https://www.lib.ncsu.edu/staff/csbaile3))
Digital Research and Scholarship Librarian
Copyright and Digital Scholarship Center
[NC State University Libraries](https://www.lib.ncsu.edu)


<a id="org33ee07c"></a>

# Exploratory text analysis

What is exploratory text analysis? Sometimes researchers working on a project approach their text corpora with clear research questions, predetermined methods, and a clear sense of the quality and nature of the corpora. You may know you are going to use some sort of classification method, and the corpus is well-described with metadata and already cleaned. Much of the time, though, we&rsquo;re working with text corpora that haven&rsquo;t been cleaned, and aren&rsquo;t well described. We might have large collections of text from the internet, or be working with a collections of digitized novels that come from multiple sources with varying quality of metadata. You might have a set of a couple of hundred interviews that have been automatically transcribed, and not checked for accuracy. In these cases, even if you know your research questions and have a sense of method or approach, you&rsquo;ll rarely be able to simply start on your analysis, whether you&rsquo;re writing code or not. You first need to take time to explore the text data you have, to get a sense of the quality of the data and their contents. You need to develop a sense of the shape of your data across documents, and understand potential features that might be relevant to your preliminary questions.

This is exploratory text analysis, this stage where we get to know our texts. Our goal today is to explore two open source tools that don&rsquo;t require the capacity to write code, but that still provide tremendous value in the research process. Depending on your research questions and methods, either tool may actually be sufficient for your research, but either or both could operate as first step in a research process that involves other tools, whether in code or not.


<a id="orgddff2dc"></a>

# Voyant


<a id="org6debaa8"></a>

## Installing Voyant vs using the hosted web version

Download and install page: <https://digihum.mcgill.ca/voyant/resources/run-your-own/voyant-server/>

Advantage in speed and corpus size since you can modify the memory available to Voyant.


<a id="org1415ed8"></a>

## File types and corpus building

Voyant can handle single documents, either by uploading them or simply copying text into the Voyant home screen input box. It provides even more power, though, when you upload many documents as a corpus.

Supported file types:

-   plain text: .txt
-   HTML: .htm, .html
-   XML: .xml
-   Word: .doc, .docx
-   RTF: .rtf
-   PDF: .pdf


<a id="org202cd54"></a>

## Exploring the interface

-   Basic layout
-   Getting help for each tool
-   Settings for each tool
-   Clicking on a document or word in one tool typically causes the other tools to update accordingly


<a id="org0184ede"></a>

## Tools of note

-   Summary
-   Contexts
-   Correlations
-   Trends
-   Topics (Hidden by default)


<a id="orgab3fe6c"></a>

## Exporting results

-   Exporting visualizations
-   Exporting data


<a id="org192ebad"></a>

# Taguette


<a id="org61e88e5"></a>

## Installing Taguette vs using the hosted web version

Download and install page: <https://www.taguette.org/install.html>


<a id="org8a3413f"></a>

## File types


<a id="orgd2b0a76"></a>

## Coding documents

-   Single level and hierarchical coding


<a id="orgd2b5ab3"></a>

## Exporting results

-   Exporting collated tagged texts


<a id="org7c69b03"></a>

# Putting it together: between distant and close reading

Research, especially with data, is iterative. We learn something from or about our data through visualization or applying some method or tool. With what we learn, we come back to our data with new interpretive possibilities and with new ideas.

Working with Voyant and Taguette together allows us to move between distant reading and close reading. In Voyant we see patterns of language across an entire corpus. We can then move into individual texts with an eye toward the patterns and themes we observed through Voyant. As we discover in individual texts new and surprising language, we can return to the corpus-level analytics of Voyant looking for correlations of those words or patterns of use over time.


<a id="org74fc53d"></a>

# Resources:

-   Voyant Docs: <https://digihum.mcgill.ca/voyant/>
-   Voyant Tools Docs: <http://docs.voyant-tools.org/tools/>
-   UC Santa Cruz Getting Started with Voyant: <https://guides.library.ucsc.edu/DSCguides/Voyant>
-   Taguette Getting Started Guide: <https://www.taguette.org/getting-started.html>
-   Illinois Library Coding with Taguette Guide: <https://guides.library.illinois.edu/qualitative/taguette>

